{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BHAKTI TIME - Backpropagation_XOR_f.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonudk/Introduction_to_AI_and_IoT-/blob/master/BHAKTI_TIME_Backpropagation_XOR_f.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ly0FEPLRRA3R"
      },
      "source": [
        "## Implementing Back-propagation Algorithm with XOR data\n",
        "\n",
        "### XOR data: <br>\n",
        "**$ x_0 \\ x_1 \\ y$** <br>\n",
        "$0 \\ \\ \\  0 \\ \\ \\  0$ <br>\n",
        "$0 \\ \\ \\  1 \\ \\ \\  1$ <br>\n",
        "$1 \\ \\ \\  0 \\ \\ \\  1$<br>\n",
        "$1 \\ \\ \\  1 \\ \\ \\  0$<br>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iewd7ysumt1L",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYnKrpHRC88X"
      },
      "source": [
        "##Activation function\n",
        "\n",
        "Sigmoid function $$\\frac{1}{1+ e^{-x}} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "RR5ReWLb0rQ8",
        "nbgrader": {
          "checksum": "f4effe0bb558b3f87da12a7a5133ee75",
          "grade": false,
          "grade_id": "cell-d84ad9dbcb889c3f",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "#Define our activation function\n",
        "\n",
        "def sigmoid (x):\n",
        "    '''\n",
        "    Input:\n",
        "        x: numpy array of any shape\n",
        "    Output:\n",
        "        y: numpy array of same shape as x\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    return (1/(1+np.exp(-x))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "4q5l-n3LkamT",
        "nbgrader": {
          "checksum": "8556b6d6d8fb50561b6a4b23e4f428e2",
          "grade": true,
          "grade_id": "cell-80b53c7b5034f924",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "0657a873-d713-4edf-d7b9-558c4b468da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''Testing'''\n",
        "assert sigmoid(0)==0.5\n",
        "assert np.isclose(sigmoid(-2), 0.119202922, atol=0.0001)\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "hAS1d1_Wkama",
        "nbgrader": {
          "checksum": "b5988d9e371e77c56c63d315f5c63d3e",
          "grade": false,
          "grade_id": "cell-9ebb909521c85d2b",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# Define the activation function derivative\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    '''\n",
        "    Input:\n",
        "        x: numpy array of any shape\n",
        "    Output:\n",
        "        y: numpy array of same shape as x\n",
        "        y = derivative of sigmoid\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    return x*(1-x)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "D27idxL-kami",
        "nbgrader": {
          "checksum": "d980605ecd57b9e69ac9a07ec6cfbc06",
          "grade": true,
          "grade_id": "cell-8668ae928d66bf7c",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "f6e534b7-4a9a-453f-d4dc-de53058ffccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''Testing code for sigmoid_derivative'''\n",
        "assert sigmoid_derivative(1) == 0\n",
        "assert sigmoid_derivative(0) == 0\n",
        "print('Test passed', '\\U0001F44D')\n"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7QEVx1qpYo3m"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "QiXPUCkdP5ky",
        "nbgrader": {
          "checksum": "4646c91497019ffdff3cd615c01b92a9",
          "grade": false,
          "grade_id": "cell-4a7dcd60006d48dc",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "#Define the NeuralNetwork class\n",
        "# why we do testing it is for our clearence that before we judge our model we should be sure that what we have written in codee matches with mathematics that we didi on paper\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, net_arch):\n",
        "        '''    \n",
        "        Input:\n",
        "            net_arch: list of 3 integers\n",
        "        Action:\n",
        "            Creates instance variables:\n",
        "                self.input: np array of shape (ni,1)\n",
        "                self.layer1: nprarray of shape (nh,1)\n",
        "                self.output: np array of shape (no,1)\n",
        "                self.weights1: np array of shape (nh, ni), initialized randomly between (-1,1)\n",
        "                self.weights2: np array of shape (no, nh), initialized randomly between (-1,1)\n",
        "                \n",
        "            NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n",
        "        '''\n",
        "        ni = net_arch[0]  ## Number of neurons in input layer    \n",
        "        nh = net_arch[1]  ## Number of neurons in hidden layer\n",
        "        no = net_arch[2]  ## Number of neurons in output layer\n",
        "        \n",
        "        self.ni = ni\n",
        "        self.nh = nh\n",
        "        self.no = no\n",
        "        \n",
        "        self.input = np.empty([self.ni,1])\n",
        "        self.layer1 = np.empty([self.nh,1])\n",
        "        self.output = np.empty([self.no,1])\n",
        "        \n",
        "        # YOUR CODE HERE\n",
        "        '''w=np.zeros((nh,ni))\n",
        "        for i in range(nh):\n",
        "          for j in range(ni):\n",
        "            w[i][j]=np.random.random()'''\n",
        "        np.random.seed(10)\n",
        "        self.weights1 = 2 * np.random.random((self.nh,self.ni)) - 1\n",
        "        self.weights2 = 2 * np.random.random((self.no,self.nh)) - 1        \n",
        "        \n",
        "    def feedforward(self,x):\n",
        "        '''\n",
        "        Input:\n",
        "            x: numpy array of shape (ni,1)\n",
        "        Action:\n",
        "            \n",
        "        Return:\n",
        "            output: numpy array of shape (no,1),\n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        # this is for first layer\n",
        "        h1=np.dot(self.weights1,x)\n",
        "        v=np.zeros((self.nh,1))\n",
        "        for i in range(h1.shape[0]):\n",
        "          v[i]=sigmoid (h1[i])\n",
        "        # it is for second layer\n",
        "        h2=np.dot(self.weights2,v)\n",
        "        y=np.zeros((self.no,1))\n",
        "        for i in range(h2.shape[0]):\n",
        "          y[i]=sigmoid (h2[i])\n",
        "        return y#,v  \n",
        "             \n",
        "\n",
        "    def backprop(self,x,y,eta):\n",
        "        '''\n",
        "        ########### DOUBT : will v change with back propagation and do we need to use changed v in this function ############\n",
        "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
        "        Input:\n",
        "            x: numpy array of shape (ni,1)\n",
        "            y: numpy array of shape (no,1)\n",
        "            eta: learning rate\n",
        "        Action:\n",
        "        # Finding the derivatives\n",
        "            del_weights2: np array of shape (no,nh) that stores the derivative of the loss function with respect to weights2\n",
        "            del_weights1: np array of shape (nh,ni) that stores the derivative of the loss function with respect to weights1\n",
        "            \n",
        "        # Update the weights with the derivative of the loss function\n",
        "            weights1 += eta*del_weights1\n",
        "            weights2 += eta*del_weights2\n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        y_feed=self.feedforward(x)# self input ka kya karna h\n",
        "        # to create what to do should I define new function\n",
        "        # creating input for next layer (means 'v')\n",
        "        h1=np.dot(self.weights1,x)\n",
        "        v=np.zeros((self.nh,1))\n",
        "        for i in range(h1.shape[0]):\n",
        "          v[i]=sigmoid (h1[i])\n",
        "        #for second layer\n",
        "        for i in range(self.no):\n",
        "          for j in range(self.nh):\n",
        "            self.weights2[i][j] = self.weights2[i][j] + eta * (y[i] - y_feed[i]) * (y_feed[i] * (1 - y_feed[i])) * v[j]\n",
        "        # preparing delta1\n",
        "        delta1=[]\n",
        "        for j in range(self.nh):\n",
        "          t = 0\n",
        "          for i in range(self.no):\n",
        "            t = t + (self.weights2[i][j] * (y[i] - y_feed[i]) * (y_feed[i] * (1 - y_feed[i])))     #### be careful about {[i][j]} things it is tricky part\n",
        "          delta1.append(t)\n",
        "        \n",
        "        # for first layer\n",
        "        for i in range(self.nh):\n",
        "          for j in range(self.ni):\n",
        "            self.weights1[i][j] = self.weights1[i][j] + eta * delta1[i] * (v[i] * (1 - v[i])) * x[j]\n",
        "            \n",
        "        return\n",
        "          \n",
        "\n",
        "    def fit(self, X, Y, eta, epochs):\n",
        "        '''\n",
        "        input:\n",
        "        X: training input data of shape (4,2)\n",
        "        Y: training output of shape (4,1)\n",
        "        eta: learning rate\n",
        "        epochs: number of epochs\n",
        "        Action:\n",
        "        # Modify the input by adding ones of shape(4,1) \n",
        "        # Set up the feed-forward propagation for the modified input   \n",
        "        # Set up the back-propagation of the error to adjust the weights\n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        X = np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
        "        for i in range(epochs):\n",
        "          for j in range(X.shape[0]):\n",
        "            \n",
        "            self.feedforward(X[j].T)\n",
        "            self.backprop(X[j].T,Y,eta)\n",
        "        \n",
        "        return\n",
        "        \n",
        "    def predict(self,x,y):\n",
        "        '''\n",
        "        # Predict function is used to check the prediction result of the neural network\n",
        "        Input:\n",
        "        x: single input data of shape (1,3)\n",
        "        y: single output data of shape (1,1)\n",
        "        Action\n",
        "        pred_out: predict the output based on the model using feedforward\n",
        "        \n",
        "        Output\n",
        "        error: y - pred_out\n",
        "        \n",
        "        \n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        y_pred = self.feedforward(x)\n",
        "        error = y - y_pred\n",
        "        return(error)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "6gp5eg0skamy",
        "nbgrader": {
          "checksum": "01c984c866bc53a22934b3a8a85bb6ae",
          "grade": true,
          "grade_id": "cell-640694d6a41609e8",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "c710a689-5954-4fd4-a2fa-bc691d1032e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''Testing code for __init__'''\n",
        "\n",
        "net_arch = [3,4,1]\n",
        "nn1 = NeuralNetwork(net_arch)\n",
        "assert nn1.input.shape == (3,1)\n",
        "assert nn1.layer1.shape == (4,1)\n",
        "assert nn1.output.shape == (1,1)\n",
        "assert np.all(nn1.weights1 < 1)\n",
        "print('Test passed', '\\U0001F44D')\n"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "hP6uPl-2kanA",
        "nbgrader": {
          "checksum": "2bcf8c9fbcf3690b31a8c6a9cde70928",
          "grade": true,
          "grade_id": "cell-f0a271c06ea8c25b",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "160b8f9f-7168-42d0-8ed6-aa7f920460c8"
      },
      "source": [
        "\n",
        "'''Testing code for feedforward'''\n",
        "\n",
        "def feedforward_original(nn1,x):\n",
        "    assert x.shape == (nn1.ni, 1)\n",
        "    layer1 = sigmoid(np.dot(nn1.weights1, x))\n",
        "    output = sigmoid(np.dot(nn1.weights2, layer1))\n",
        "    return output\n",
        "x = np.array([0,1,1]).reshape(-1, 1)\n",
        "assert nn1.feedforward(x) == feedforward_original(nn1, x)\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "XBXXqFAKYxnv",
        "nbgrader": {
          "checksum": "3737666b17aaad1d4a58603c7b67ce81",
          "grade": true,
          "grade_id": "cell-a4a2893378d844f3",
          "locked": true,
          "points": 4,
          "schema_version": 1,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4ee2233-73c9-435e-8b03-20360c1c8388"
      },
      "source": [
        "'''Testing code for backprop'''\n",
        "def backprop_original(nn1,x,y,eta):\n",
        "    weights1 = nn1.weights1\n",
        "    weights2 = nn1.weights2\n",
        "    del_weights2 = np.dot(((y - nn1.output) * sigmoid_derivative(nn1.output)),nn1.layer1.reshape(-1, 1).T)\n",
        "    del_weights1 = np.dot(((y - nn1.output) * sigmoid_derivative(nn1.output)*nn1.weights2.T * sigmoid_derivative(nn1.layer1)), x.T)\n",
        "\n",
        "    # update the weights with the derivative (slope) of the loss function\n",
        "    weights1 += eta*del_weights1\n",
        "    weights2 += eta*del_weights2\n",
        "    return(weights1, weights2)\n",
        "\n",
        "x = np.array([0,1,1]).reshape(-1, 1)\n",
        "y = np.array([[0],])\n",
        "eta = 1\n",
        "nn1.backprop(x, y, eta)\n",
        "w1, w2 = backprop_original(nn1, x, y, eta) \n",
        "assert np.all(np.isclose(w1, nn1.weights1))\n",
        "assert np.all(np.isclose(w2, nn1.weights2))\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tUs7Wwu7ZjBX"
      },
      "source": [
        "## Fitting the data (Training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "kbRcD6R6RBpw",
        "nbgrader": {
          "checksum": "dbbf11073bfdce0010e10e0eaca6500c",
          "grade": false,
          "grade_id": "cell-e59bb4a5a7ddab07",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "## CHECK THE PERFORMANCE\n",
        "'''\n",
        "Input:\n",
        "# Set the input data\n",
        "X = ([[0.1, 0.1], [0.1, 0.9],\n",
        "                [0.9, 0.1], [0.9, 0.9]])\n",
        "# Set the labels, the correct results for the xor operation\n",
        "Y = ([[0.1], [0.9], \n",
        "                 [0.9], [0.1]])\n",
        "Action:\n",
        "# Initialize the NeuralNetwork with\n",
        "# 3 input neurons\n",
        "# 4 hidden neurons\n",
        "# 1 output neuron\n",
        "\n",
        "# Fit the datas\n",
        "'''\n",
        "# YOUR CODE HERE\n",
        "\n",
        "nn1 = NeuralNetwork([3,4,1])\n",
        "\n",
        "X = np.array([[0.1, 0.1], [0.1, 0.9],[0.9, 0.1], [0.9, 0.9]])\n",
        "\n",
        "Y = np.array([[0.1], [0.9],[0.9], [0.1]])\n",
        "\n",
        "nn1.fit(X,Y,eta,epochs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "-aYoNXSF2f9F",
        "nbgrader": {
          "checksum": "b1a894b26291672207fabd649f07486d",
          "grade": true,
          "grade_id": "cell-7391ad1a93e30118",
          "locked": true,
          "points": 3,
          "schema_version": 1,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9986b5e6-e11b-4cf3-ad9f-107e5dd57e06"
      },
      "source": [
        "'''Testing for fit'''\n",
        "X = np.array([[0.1, 0.1], [0.1, 0.9],\n",
        "                [0.9, 0.1], [0.9, 0.9]])\n",
        "# Set the labels, the correct results for the xor operation\n",
        "Y = np.array([[0.1], [0.9], \n",
        "                 [0.9], [0.1]])\n",
        "nn1.fit(X,Y,1,10000)\n",
        "x = np.array([1,1,1]).reshape(-1, 1)\n",
        "y = np.array([[0],])\n",
        "print(nn1.feedforward(x),y)\n",
        "assert np.all(np.isclose(nn1.feedforward(x),y,atol=0.11))\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.09926878]] [[0]]\n",
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SLXYzUB4fs8o"
      },
      "source": [
        "## Plotting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H2XKM2sufuwL",
        "colab": {}
      },
      "source": [
        "def plotting(X, Y):\n",
        "  x_plot = X.T\n",
        "  color = []\n",
        "  for i in Y:\n",
        "    if i[0] == 0:\n",
        "      color.append('r')\n",
        "    else:\n",
        "      color.append('b')\n",
        "  color = np.array(color)\n",
        "  print(x_plot)\n",
        "  plt.figure()\n",
        "  plt.xlabel('x1')\n",
        "  plt.ylabel('x2')\n",
        "  plt.scatter(x_plot[0],x_plot[1],color=color)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PWvKv62qsiLP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "3461f46b-2de8-4f85-dba1-af01f3befc19"
      },
      "source": [
        "plotting(X, Y)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1 0.1 0.9 0.9]\n",
            " [0.1 0.9 0.1 0.9]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkor/B8p3GN8IxuaTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K1PPPHD9aDM-"
      },
      "source": [
        "## Could you test it now?\n",
        "\n",
        "Find the error between the predicted output and the desired output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGQZuMbihk-1",
        "colab": {}
      },
      "source": [
        "def testing(X, Y):\n",
        "  ones = 0.9*np.ones((X.shape[0],1))\n",
        "  x_test = np.concatenate([ones, X], axis=1)\n",
        "  y_test = Y\n",
        "\n",
        "  for k in range(4):\n",
        "    print(nn.predict(x_test[k].reshape(-1, 1),y_test[k]))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "vMqNNPopYjPI",
        "nbgrader": {
          "checksum": "4ff21be5bf4c5c721cbdbb0d612a9e0c",
          "grade": true,
          "grade_id": "cell-08caa0ed7b0ce465",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "150a2167-2c15-4350-e1fe-f62728505cb7"
      },
      "source": [
        "'''Testing the prediction'''\n",
        "x = np.array([0.9,0.9,0.9]).reshape(-1, 1)\n",
        "y = np.array([[0.1],])\n",
        "\n",
        "assert np.all(np.isclose(nn1.predict(x,y),0, atol=0.01))\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9-0oU2fCdhRN"
      },
      "source": [
        "# Advanced\n",
        "## Does the performance increase with increasing the number of neurons in the hidden layer?\n",
        "- Repeat the training with 1 neuron in the hidden layer, then with 3 neuron and then with 5 neuron in the hidden layer to see the trend in performance\n",
        "- Compare the training error\n",
        "- Compare the testing error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SNHBGSLBD_t2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e44d4c90-3982-4c3f-ae65-add102d3d7b5"
      },
      "source": [
        "nh_all = [1,3,5]\n",
        "train_error = np.zeros((3,4))\n",
        "test_error = np.zeros((3,4))\n",
        "X = np.array([[0.1, 0.1], [0.1, 0.9],[0.9, 0.1], [0.9, 0.9]])\n",
        "\n",
        "Y = np.array([[0.1], [0.9],[0.9], [0.1]])\n",
        "#print(Y.shape)\n",
        "eta = 1e-3\n",
        "X1 = np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
        "\n",
        "epochs = 10\n",
        "for i in range(len(nh_all)):\n",
        "  nn = NeuralNetwork([3,nh_all[i],1])\n",
        "  nn.fit(X,Y,eta,epochs)# solved probelm with any nh it may be < or > than ni\n",
        "  for j in range(X1.shape[0]):\n",
        "    train_error[i][j] = train_error[i][j] + (nn.feedforward(X1[j]) - Y[j])\n",
        "    test_error[i][j] = test_error[i][j] + (nn.predict(X1[j].T,Y[j]))\n",
        "\n",
        "print('Train errors:',train_error)    \n",
        "print('Test errors:',test_error)    \n",
        "'''train_error = train_error.reshape(12,1)\n",
        "test_error = test_error.reshape(12,1)\n",
        "\n",
        "plt.plot(train_error,test_error)'''\n"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train errors: [[ 0.46841403 -0.35459322 -0.31911859  0.45830093]\n",
            " [ 0.39655807 -0.34263684 -0.43801068  0.41915483]\n",
            " [ 0.63142091 -0.17515189 -0.18934917  0.60754846]]\n",
            "Test errors: [[-0.46841403  0.35459322  0.31911859 -0.45830093]\n",
            " [-0.39655807  0.34263684  0.43801068 -0.41915483]\n",
            " [-0.63142091  0.17515189  0.18934917 -0.60754846]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_error = train_error.reshape(12,1)\\ntest_error = test_error.reshape(12,1)\\n\\nplt.plot(train_error,test_error)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    }
  ]
}