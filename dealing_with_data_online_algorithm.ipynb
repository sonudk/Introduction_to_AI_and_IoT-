{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dealing_with_data_online_algorithm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonudk/Introduction_to_AI_and_IoT-/blob/master/dealing_with_data_online_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VsGBvYtQfuZj"
      },
      "source": [
        "# <center> Dealing With Data </center>\n",
        "## <center> Linear Separatrix -   Making it online  </center>\n",
        "### <center> Prof. Laxmidhar Behera </center>\n",
        "### <center> IIT Kanpur </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UuCN4ymyhVQp"
      },
      "source": [
        "\n",
        "\n",
        "- Given data and linear model, data can be represented in terms of the following expression - <br>\n",
        "$Aw = y$ &nbsp; $A \\in R^{1\\times n}$ &nbsp; $w \\in R^{n\\times m}$ &nbsp; $y \\in R^{1\\times m}$ <br><br>\n",
        "- The methods like least square solution and minimum norm solution are generally offline techniques.\n",
        "-   To learn the unknown parameters in an online way , i.e., to update $w$ as we see the new data, we define a cost or loss function and then minimize it using an algorithm called gradient descent.\n",
        "- **Cost(or Loss) function**:\n",
        "It is a function of the difference between estimated and true values for an instance of data.-<br>\n",
        "<center>$E = \\frac{1}{2} \\sum_{i=1}^m (y_i^d - y_i)^2$<br></center>\n",
        "  where $y_i^d$ is the desired $i^{th}$output and $y_i$ is the calculated $i^{th}$ output for a single data point. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ueXQ0bw2wwtA"
      },
      "source": [
        "- To minimize this loss function, we use a method called <b> Gradient Descent</b> \n",
        "\n",
        "\n",
        "## <center>  Gradient Descent  </center>\n",
        "- In this , we update the unknown parameters iteratively for finding the minimum of a function .\n",
        "-  In this algorithm, we first compute the slope or gradient of the function at the current point.\n",
        "- The algorithm then takes steps in the direction opposite to the direction of the gradient at the current point.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1z3HXUPpzx8fTjkYXf9i9sxTQidE-C6Wx\" alt=\"Drawing\" style=\"width: 200px;\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsu-D3PjFa3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a1CHdIGFItTZ"
      },
      "source": [
        "### <center>Loading Data in python</center>\n",
        "Sklearn.datasets  is a library of many standard datasets including iris data <br>\n",
        "Numpy is a numerical processing library in python <br>\n",
        "Keras is a python library for building deep neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HSoIps3TPkkE",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(10) # For random weight initialization\n",
        "\n",
        "iris = load_iris() # iris is a python dictionary with key-value pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zTbdPqu2I3Bh"
      },
      "source": [
        "#### Pre-process Data\n",
        "Convert labels to categorical - One-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6FbnHxSfPp_i",
        "outputId": "a5bcfe31-8f8d-4f45-9458-b8ca759f0c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = iris['data']\n",
        "Y = iris['target']\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "Ny = len(np.unique(Y)) # Ny is number of categories/classes\n",
        "\n",
        "\n",
        "Y = to_categorical(Y[:], num_classes = Ny) # "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ka3K4QbUI-7k"
      },
      "source": [
        "#### Train - Test split\n",
        "#### Data Normalization/Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UkcAwMTcP5A7",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#we use these standeredscaler to normalize our data or shpuld say to preprocess\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train) # Computes the mean and standard deviation\n",
        "\n",
        "X_train = scaler.transform(X_train) # Perform transformation: x = (x-mean)/std\n",
        "X_test = scaler.transform(X_test)# here it uses mean and stddev that we get from train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1-EoOFlGQNL2",
        "colab": {}
      },
      "source": [
        "# define function to add column of 1's\n",
        "addlcol = lambda x: np.concatenate((x, np.ones((x.shape[0], 1))), axis = 1)\n",
        "A = addlcol(X_train)\n",
        "# why we are doing it\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ha6Ru8G3N1Ts",
        "outputId": "f9efdacd-0e18-4139-9cd6-0db29ab68bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "A.shape\n",
        "print(A[9].shape)\n",
        "print(Y_train.shape)\n",
        "print(A[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5,)\n",
            "(120, 3)\n",
            "[ 0.31553662 -0.04578885  0.44767531  0.23380268  1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t31lCCjmLExW"
      },
      "source": [
        "# Weight update using gradient descent\n",
        "\n",
        "\n",
        "\n",
        "### $w_{new} = w_{old} - \\eta \\ \\frac{\\partial E}{\\partial w} $\n",
        "\n",
        "### $E = \\frac{1}{2} \\sum_{j=1}^3 (y_j^d - y_j)^2$\n",
        "\n",
        "### ${\\frac{\\partial E}{\\partial w}}_{5\\times3} = - \\sum_{j=1}^3 (y_j^d - y_j) A = - A^T_{5\\times1} e_{1\\times3}  $\n",
        "\n",
        "### $w_{new} = w_{old} + \\eta A^T e \\ \\ \\ \\ \\ \\ \\ \\ (1)$\n",
        "\n",
        "### Algorithm\n",
        "\n",
        "- Initialize random weights between (-0.5 , 0.5)\n",
        "\n",
        "For each sample, \n",
        "- First calculate y = Aw \n",
        "- Find error(e) = $y^d - y$\n",
        "- Update weights using (1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT_HgQeLKsBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "0aecb2a9-20d4-4317-8c2f-b6f2ac2a8574"
      },
      "source": [
        "# this is fixed w now what if we do random then we will not be able to judge our model and make better leraner\n",
        "# when do same assignment with gradient descent\n",
        "#np.random.seed(10)\n",
        "w=(2*np.random.rand(5,3) - 1)/2\n",
        "print(w.shape)\n",
        "y=np.dot(A,w)\n",
        "print(y[1].shape)\n",
        "eta=0.06\n",
        "for i in range(A.shape[0]):\n",
        "  error=Y_train[i]-y[i]\n",
        "  \n",
        "  w = w + eta*np.dot(A[i].reshape(5,1),error.reshape(1,3))\n",
        "  #print(w)\n",
        "print(w)  \n",
        "'''#print(y.shape)\n",
        "sum_error=np.zeros((120,3))\n",
        "for i in range(y.shape[0]):\n",
        "  sum_error[i]=((Y_train[i]-y[i]))\n",
        "e=Y_train-y\n",
        "#print(e)\n",
        "#e=np.sum(sum_error,axis=0)\n",
        "#print(e)\n",
        "print(e.shape)\n",
        "eta=0.06\n",
        "w=w+eta*np.dot(A.T,e)\n",
        "print(w)\n",
        "#w[i]=w-eta*np.dot(A.T[],e)\n",
        "#these two are methods for eta updation adagrade,adam'''"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 3)\n",
            "(3,)\n",
            "[[-2.15268251  4.30986391 -1.18654834]\n",
            " [ 1.2922554  -4.15212258  2.34462875]\n",
            " [-3.05674971  5.40161921 -1.63960197]\n",
            " [-2.40248727  4.63995565 -1.07095225]\n",
            " [ 0.52173018  5.06122556 -0.23281654]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#print(y.shape)\\nsum_error=np.zeros((120,3))\\nfor i in range(y.shape[0]):\\n  sum_error[i]=((Y_train[i]-y[i]))\\ne=Y_train-y\\n#print(e)\\n#e=np.sum(sum_error,axis=0)\\n#print(e)\\nprint(e.shape)\\neta=0.06\\nw=w+eta*np.dot(A.T,e)\\nprint(w)\\n#w[i]=w-eta*np.dot(A.T[],e)\\n#these two are methods for eta updation adagrade,adam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z5P07QvlSZZ7",
        "outputId": "da80dc8f-f598-4d0e-e5f0-9fa6f0341bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''w = (2*np.random.rand(5,3) - 1)/2\n",
        "\n",
        "eta = 0.06\n",
        "for i in range(A.shape[0]):\n",
        "  y = (A[i].reshape(1,5)).dot(w)\n",
        "  yd = Y_train[i]\n",
        "  e = yd-y\n",
        "  w = w + eta*(A[i].reshape(5,1)).dot(e.reshape(1,3))\n",
        "  \n",
        "print('weights are \\n', w)'''"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"w = (2*np.random.rand(5,3) - 1)/2\\n\\neta = 0.06\\nfor i in range(A.shape[0]):\\n  y = (A[i].reshape(1,5)).dot(w)\\n  yd = Y_train[i]\\n  e = yd-y\\n  w = w + eta*(A[i].reshape(5,1)).dot(e.reshape(1,3))\\n  \\nprint('weights are \\n', w)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eHY14HVebavY",
        "outputId": "a26cb59c-50ec-4a80-dc9a-8f4b7dd64a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def evaluate(X, W, Yd, transform_X_a):\n",
        "  a = transform_X_a(X)\n",
        "  yd = np.argmax(Yd, axis = 1)\n",
        "  y = np.argmax(a.dot(W), axis = 1)\n",
        "  print('Confusion Matrix:')\n",
        "  print(confusion_matrix(yd, y))\n",
        "\n",
        "\n",
        "evaluate(X_train, w, Y_train, addlcol)\n",
        "evaluate(X_test, w, Y_test, addlcol)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[ 0 39  0]\n",
            " [26 11  0]\n",
            " [43  1  0]]\n",
            "Confusion Matrix:\n",
            "[[ 0 11  0]\n",
            " [12  1  0]\n",
            " [ 6  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s8WongYWJ3aa"
      },
      "source": [
        "# Second Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kycdY4aZJgUg"
      },
      "source": [
        "<table>\n",
        "  <tr>\n",
        "    <th colspan=\"0\">X</th>\n",
        "      <th colspan=\"4\">Y</th>\n",
        "      <th colspan=\"6\"></th>\n",
        "      </tr> \n",
        "  <tr>\n",
        "      <td>0.31</td><td>-0.04</td><td>0.45</td><td>0.23</td><td>0</td><td>1</td><td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>2.24</td><td>-0.46</td><td>1.30</td><td>1.40</td><td>0</td><td>0</td><td>1</td>\n",
        "      </tr>\n",
        "</table>\n",
        "\\begin{align}\n",
        "[l_s\\: b_s\\: l_p\\: b_p\\: l_s^2\\: b_s^2\\: l_p^2\\: b_p^2\\: 1] \\begin{bmatrix}\n",
        "          w_{00} &w_{01} &w_{02}\\\\\n",
        "          w_{10} &w_{11} &w_{12}\\\\\n",
        "          \\vdots &\\vdots &\\vdots \\\\\n",
        "          w_{80} &w_{81} &w_{82}\n",
        "         \\end{bmatrix} = [y_0\\: y_1\\: y_2]\n",
        "\\end{align}\n",
        "<br><br>\n",
        "<center>Aw = y</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "45VmohB0bQ1N",
        "outputId": "47c02f77-c3d1-4c28-b8ad-27b7811be246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "addSqlcol = lambda x: np.concatenate((x, x**2, np.ones((x.shape[0], 1))), axis = 1)\n",
        "\n",
        "A = addSqlcol(X_train)\n",
        "Y = Y_train\n",
        "\n",
        "A.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XqNogAVMmvS7",
        "outputId": "145bda2f-c19b-4665-b1b7-0fc88c636ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "eta = 0.05\n",
        "w = (2*np.random.rand(9,3) - 1)/2\n",
        "\n",
        "\n",
        "for i in range(A.shape[0]):\n",
        "  y = (A[i].reshape(1,9)).dot(w)\n",
        "  yd = Y_train[i]\n",
        "  e = yd-y\n",
        "  w = w + eta*(A[i].reshape(9,1)).dot(e.reshape(1,3))\n",
        "\n",
        "\n",
        "evaluate(X_train, w, Y_train, addSqlcol)\n",
        "evaluate(X_test, w, Y_test, addSqlcol)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[39  0  0]\n",
            " [ 0 34  3]\n",
            " [ 0  4 40]]\n",
            "Confusion Matrix:\n",
            "[[11  0  0]\n",
            " [ 0  8  5]\n",
            " [ 0  1  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HXxNp0yZqIqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "599f2175-7be6-427e-ae0c-f3c07710a4db"
      },
      "source": [
        "#append,reverse,index,\n",
        "'''\n",
        "slicing and negative index and also try\n",
        "tupl=(1,2,3)\n",
        "pritn(tupl)\n",
        "tupl=tupl+(3,)# we use comma here to differentiate '''\n",
        "def padding_list(list1,max_ele):\n",
        "  for i in range(len(list1)):\n",
        "    if len(list1[i])==max_ele:\n",
        "      pass\n",
        "    else:\n",
        "      for j in range(max_ele-len(list1[i])):\n",
        "        list1[i].append(0)\n",
        "  \n",
        "  return list1      \n",
        "print(padding_list([[39],[ 0 ,34,  3],[ 3, 40]],3))        \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[39, 0, 0], [0, 34, 3], [3, 40, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCryloM-CI6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}