{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "190606_kerasbasics_gaussian-assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonudk/Introduction_to_AI_and_IoT-/blob/master/190606_kerasbasics_gaussian_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwu_H0V1M9A6",
        "colab_type": "text"
      },
      "source": [
        "# Keras Basics\n",
        "We will learn about\n",
        "* Dense layers\n",
        "* Categorical cross-entropy\n",
        "\n",
        "A toy example to show how to train a classifier with Keras and use it. The data comes from three gaussian distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_F5JP-dM9A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DATA GENERATION\n",
        "import numpy as np\n",
        "\n",
        "def generateX(cls):\n",
        "    '''\n",
        "    Inputs:\n",
        "        cls: class {0, 1, 2}\n",
        "    Outputs:\n",
        "        a sample from cls\n",
        "    '''\n",
        "    assert cls in [0,1,2]\n",
        "    if cls==0:\n",
        "        return np.random.normal(np.array([0,0]),100)\n",
        "    elif cls==1:\n",
        "        return np.random.normal(np.array([200,200]),100)\n",
        "    elif cls==2:\n",
        "        return np.random.normal(np.array([-200,200]),100)\n",
        "    assert False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8C0ZHLrM9BM",
        "colab_type": "text"
      },
      "source": [
        "Could you write a function to generate N samples from class 0 and N samples from class 1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS3llbqhM9BO",
        "colab_type": "code",
        "outputId": "b977e18d-f7b9-480b-cfea-c3100a013c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def generateXY(N):\n",
        "    '''\n",
        "    Inputs:\n",
        "        N: no. of samples of each class\n",
        "    '''\n",
        "    Y = []\n",
        "    X = []\n",
        "    for cls in range(3):\n",
        "        for i in range(N):\n",
        "            y = cls\n",
        "            x = generateX(y)\n",
        "            x = x.reshape(-1, 1).T\n",
        "            Y.append(y)\n",
        "            X.append(x)\n",
        "    X = np.concatenate(X, axis=0)\n",
        "    print(X.shape, 'X.shape')\n",
        "    print(np.array(Y).shape)\n",
        "    Y = np.array(Y).reshape(-1,1)\n",
        "    print(X.shape)\n",
        "    print(Y.shape)\n",
        "    return X, Y\n",
        "\n",
        "# def generateXY(N):\n",
        "#     '''\n",
        "#     Inputs:\n",
        "#         N: no. of samples of each class\n",
        "#     '''\n",
        "#     Y = [0]*N + [1]*N + [2]*N   # a list of 0s and 1s as ground truth classes  \n",
        "#     X = [generateX(y) for y in Y]  # samples corresponding to the ground truth Y\n",
        "#     X = np.vstack(X)   # arrange samples in different rows\n",
        "#     Y = np.array(Y).reshape(-1,1)\n",
        "#     return X, Y\n",
        "\n",
        "X_train, Y_train_int = generateXY(50)\n",
        "# Nx = X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 2) X.shape\n",
            "(150,)\n",
            "(150, 2)\n",
            "(150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF-wtxZlM9BX",
        "colab_type": "code",
        "outputId": "e763a9dc-85b6-463a-8250-6d2820510c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "def test_generateXY():\n",
        "    X_train, Y_train = generateXY(50)\n",
        "    assert X_train.shape==(150,2)\n",
        "    assert Y_train.shape==(150,1)\n",
        "    print(\"OK\")\n",
        "test_generateXY()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 2) X.shape\n",
            "(150,)\n",
            "(150, 2)\n",
            "(150, 1)\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtdHtV8oM9Bk",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encoding\n",
        "\n",
        "Now our Y is in the form [0], [1] and [2]. We want to convert them to [1,0,0], [0,1,0] and [0,0,1], respectively. \n",
        "Could you write a code to convert Y (with one column) into one-hot encoded Y (with 3 columns)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGsCK-1yM9Bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneHot(y, Ny):\n",
        "    '''\n",
        "    Input:\n",
        "        y: an int in {0, 1, 2}\n",
        "        Ny: Number of classes, e.g., 3 here.\n",
        "    Output:\n",
        "        Y: a vector of Ny (=3) tuples\n",
        "    '''\n",
        "    Y = np.zeros(Ny)\n",
        "    Y[y] = 1\n",
        "    return Y\n",
        "\n",
        "Ny = 3\n",
        "Y_train = np.array([oneHot(y,Ny) for y in Y_train_int])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbps14rJM9Br",
        "colab_type": "code",
        "outputId": "c30a5e4a-426d-42b7-a0d2-01024da92794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def test_oneHot():\n",
        "    assert np.all(oneHot(0,3)==np.array([1,0,0]))\n",
        "    assert np.all(oneHot(1,3)==np.array([0,1,0]))\n",
        "    assert np.all(oneHot(2,3)==np.array([0,0,1]))\n",
        "    assert Y_train.shape[1]==3\n",
        "    print(\"OK\")\n",
        "test_oneHot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_-e2roJM9B0",
        "colab_type": "text"
      },
      "source": [
        "### Input Normalization\n",
        "X can lie in any unbounded range. We need to curtail to a narrow range close to zero. This helps in enhancing the stability of training and hyper-parameter tuning.\n",
        "This is normally achieved by scaling the X to have zero mean and unit standard deviation (std).\n",
        "\n",
        "$X \\leftarrow \\frac{X-mean(X)}{std(X)}$, where this is element wise division\n",
        "\n",
        "Could you use training samples to find mean and std, and normalize your X_train with that?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByV7uf03M9B3",
        "colab_type": "code",
        "outputId": "96acf5ce-613c-425f-c507-66530e541ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2617
        }
      },
      "source": [
        "def findMeanStddev(X):\n",
        "    '''\n",
        "    Input: \n",
        "        X: a matrix of size (no. of samples, dimension of each sample)\n",
        "    Output:\n",
        "        mean: mean of samples in X (same size as X)\n",
        "        stddev: element-wise std dev of sample in X (same size as X)\n",
        "    '''\n",
        "    mean = np.sum(X, axis=0)/X.shape[0]\n",
        "    X1 = X-mean\n",
        "    stddev = np.sqrt(np.sum(X1*X1, axis=0)/X.shape[0])\n",
        "    return mean, stddev\n",
        "\n",
        "def normalizeX(X, mean, stddev):\n",
        "    '''\n",
        "    Input:\n",
        "        X: a matrix of size (no. of samples, dimension of each sample)\n",
        "        mean: mean of samples in X (same size as X)\n",
        "        stddev: element-wise std dev of sample in X (same size as X) \n",
        "    Output:\n",
        "        Xn: X modified to have 0 mean and 1 std dev\n",
        "    '''\n",
        "    Xn = (X-mean)/(stddev+1e-8)\n",
        "    return Xn\n",
        "\n",
        "mean_train, stddev_train = findMeanStddev(X_train)\n",
        "X_train = normalizeX(X_train, mean_train, stddev_train)\n",
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.15864581 -0.09538976]\n",
            " [-0.38416621 -0.46179307]\n",
            " [ 0.15511856 -0.57090093]\n",
            " [-0.03202389 -0.84844903]\n",
            " [-0.28792207 -1.13622847]\n",
            " [-0.25574084 -1.04735405]\n",
            " [-0.02271442 -1.66589501]\n",
            " [ 0.57159686 -0.30229132]\n",
            " [-0.09261643 -1.85062457]\n",
            " [-0.67511483 -1.71770346]\n",
            " [ 0.01263637 -1.37451238]\n",
            " [ 0.56689995 -1.07411692]\n",
            " [-0.5867804  -2.4820843 ]\n",
            " [-0.5319375  -0.85157828]\n",
            " [-0.45896116 -2.09861235]\n",
            " [ 0.08343748 -1.43175988]\n",
            " [-0.54485502  0.43014782]\n",
            " [ 1.15869576 -0.44986589]\n",
            " [-0.45360911 -1.04009795]\n",
            " [ 0.05378818 -0.8000738 ]\n",
            " [-0.44738473 -1.09791295]\n",
            " [-0.00666804 -1.74479162]\n",
            " [-0.73739361 -0.85994425]\n",
            " [ 0.04938488 -1.48324196]\n",
            " [-0.02654817 -0.92465947]\n",
            " [ 0.49513196 -1.44810753]\n",
            " [-0.76237452 -0.93683489]\n",
            " [ 0.5445382  -0.17489886]\n",
            " [ 0.69541469  0.01362809]\n",
            " [-0.21640802 -0.8520114 ]\n",
            " [-0.72033359 -1.77772858]\n",
            " [-0.22759347 -0.73267151]\n",
            " [-0.54868456 -1.26293181]\n",
            " [ 0.94536177 -2.22396543]\n",
            " [ 0.43526342  0.71912427]\n",
            " [ 0.1580965  -0.68680644]\n",
            " [-0.1894933  -1.04997716]\n",
            " [ 0.08227069 -2.05190992]\n",
            " [ 0.27865358 -2.25739525]\n",
            " [-0.24989701 -0.61660526]\n",
            " [ 0.00815456 -1.13986934]\n",
            " [ 0.11686965 -0.64609514]\n",
            " [-0.55113076  0.02489746]\n",
            " [ 0.52811915 -1.12431379]\n",
            " [-0.72251963 -0.99790559]\n",
            " [-0.5291359  -1.2772071 ]\n",
            " [ 0.69891944 -1.21122798]\n",
            " [-0.17841953 -1.57877054]\n",
            " [-0.41861415 -0.24088585]\n",
            " [-0.04064145  0.066158  ]\n",
            " [ 1.40908447  0.25821199]\n",
            " [ 1.81712628  0.31791745]\n",
            " [ 2.12254162 -1.38102511]\n",
            " [ 1.56047121  0.82686636]\n",
            " [ 0.39127567  0.19041788]\n",
            " [ 0.94942382 -0.18483545]\n",
            " [ 1.79529023  0.36705913]\n",
            " [ 0.85949957 -0.82974745]\n",
            " [ 1.44734041  1.00321095]\n",
            " [ 0.54113219  0.24314308]\n",
            " [ 0.942697   -0.02925783]\n",
            " [ 0.11558091  0.93023131]\n",
            " [ 1.06598609 -0.34591448]\n",
            " [ 0.63094262 -0.48036388]\n",
            " [ 0.27831835  1.92545342]\n",
            " [ 1.07429871  1.45169886]\n",
            " [ 0.85909488  1.96212725]\n",
            " [ 1.37024664  0.04255196]\n",
            " [ 0.67336545  0.38508572]\n",
            " [ 0.74810704  0.36919226]\n",
            " [ 1.93947523  0.50783491]\n",
            " [ 1.22298973  0.30308121]\n",
            " [ 1.37351422 -0.03830788]\n",
            " [ 0.90471953 -0.44575204]\n",
            " [ 1.05334466 -0.05521837]\n",
            " [ 2.57156325  2.04108909]\n",
            " [ 1.21039374  0.10168304]\n",
            " [ 0.94874145  0.67757289]\n",
            " [ 1.5701847   0.59833993]\n",
            " [ 0.86779048  1.49944086]\n",
            " [ 1.37347497  0.85048253]\n",
            " [ 1.60672295  0.69124766]\n",
            " [ 1.3250205   0.98159258]\n",
            " [ 1.15895757  0.65075684]\n",
            " [ 1.04951892  0.5596546 ]\n",
            " [ 0.7203746   1.73385528]\n",
            " [ 1.03701781  0.78485246]\n",
            " [ 1.09250055  0.34827924]\n",
            " [ 0.76966113  0.95659483]\n",
            " [ 0.13287359  0.93481197]\n",
            " [ 1.62160335 -0.39740869]\n",
            " [ 1.45399387  0.64117524]\n",
            " [ 0.71659816 -0.75180178]\n",
            " [ 1.73972445  0.22180514]\n",
            " [ 1.21752639 -0.20388772]\n",
            " [ 0.105591    0.36476795]\n",
            " [ 1.29908495  0.1986244 ]\n",
            " [ 0.60478819  0.73288384]\n",
            " [ 0.87801209  1.86513923]\n",
            " [ 1.63236978 -0.29890084]\n",
            " [-1.93001987  1.54272065]\n",
            " [-1.17340104 -0.10670738]\n",
            " [-0.75160093  0.46177937]\n",
            " [-1.3461843   0.736364  ]\n",
            " [-1.35158299  0.26730762]\n",
            " [-0.51599678  0.46818157]\n",
            " [-1.31962284 -0.64703521]\n",
            " [-1.24394787  1.8488748 ]\n",
            " [-0.62972459  1.61569357]\n",
            " [-1.55836388  1.48316931]\n",
            " [-0.92969754 -0.27932434]\n",
            " [-0.70285331  0.98097647]\n",
            " [-1.24150682  1.09711871]\n",
            " [-0.63725426  0.38088915]\n",
            " [-0.82408406 -0.39500545]\n",
            " [-0.31254654  0.62714663]\n",
            " [-1.40084802 -0.14798815]\n",
            " [-1.42216392  0.3118589 ]\n",
            " [-1.15452169  0.89879907]\n",
            " [-0.34676716  0.60513694]\n",
            " [-1.11074359  0.37380519]\n",
            " [-0.88640066 -0.88771419]\n",
            " [-0.98582531  0.9486115 ]\n",
            " [-0.99571675  0.40756292]\n",
            " [-0.56875314  1.22010648]\n",
            " [-0.49842022  0.63086509]\n",
            " [-0.95515488  0.84272158]\n",
            " [-1.45715542  1.09282846]\n",
            " [-1.43028503 -0.83408391]\n",
            " [-0.8483195   0.98526465]\n",
            " [-0.65254676  0.75399827]\n",
            " [-0.82423612  0.04027297]\n",
            " [-1.51275344 -0.23270143]\n",
            " [-1.1453383   0.14709638]\n",
            " [-0.93286328  1.74057519]\n",
            " [-1.14433372 -0.03782044]\n",
            " [-1.84286256  0.06991266]\n",
            " [-0.9392313   0.34972414]\n",
            " [-0.9950423   0.30111637]\n",
            " [-1.3985447   0.05205913]\n",
            " [-0.26112473 -0.27028776]\n",
            " [-1.20040202  0.70690528]\n",
            " [-1.30844816  0.39091746]\n",
            " [-1.3177412   1.45984141]\n",
            " [-1.46901934  1.48067761]\n",
            " [-1.08680253  0.7363807 ]\n",
            " [-1.03617281  0.07936467]\n",
            " [-1.83694368  1.4444307 ]\n",
            " [-1.09295786  0.14162863]\n",
            " [-0.22044233  1.48371762]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyuQ0HnqM9CB",
        "colab_type": "code",
        "outputId": "d140df18-bf57-4554-b671-07c522837eef",
        "colab": {}
      },
      "source": [
        "def test_normalizeX():\n",
        "    X = np.ones((3,3))\n",
        "    m,s = findMeanStddev(X)\n",
        "    assert np.all(m==np.ones(3))\n",
        "    assert np.all(s==np.zeros(3))\n",
        "    assert np.all(normalizeX(X,m,s)==0*X)\n",
        "    assert mean_train.shape==(2,)\n",
        "    assert stddev_train.shape==(2,)\n",
        "    # test on random X\n",
        "    X = np.random.random((5,3))\n",
        "    m,s = findMeanStddev(X)\n",
        "    Xn = normalizeX(X,m,s)\n",
        "    mn, sn = findMeanStddev(Xn)\n",
        "    assert np.allclose(mn, np.zeros(3))\n",
        "    assert np.allclose(sn, np.ones(3))\n",
        "    print(\"OK\")\n",
        "test_normalizeX()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idfaqf4OM9CM",
        "colab_type": "text"
      },
      "source": [
        "### Plotting\n",
        "Could you plot all the samples in X_train with different colors for different classes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMyaxtlJM9CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
        "def plotXY(X, Y):\n",
        "    '''\n",
        "    Inputs:\n",
        "        X: a matrix of size (no. of samples, dimension of each sample)\n",
        "        Y: a matrix of size (no. of samples, no. of classes) - these are one-hot vectors\n",
        "    Action:\n",
        "        Plots the samples in X, their color depends on Y\n",
        "    '''\n",
        "    Ny = Y.shape[1]\n",
        "    for cls in range(Ny):\n",
        "        idx = np.where(Y[:,cls]==1)[0]\n",
        "        plt.plot(X[idx,0], X[idx,1], colors[cls]+'.')\n",
        "    plt.show()\n",
        "# plotXY(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hb0zbGJM9Cc",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Network\n",
        "We now create the network with dense layers: \n",
        "$y = f(Wx)$\n",
        "\n",
        "ReLU activation: \n",
        "$f(h) = h, h>0; 0, h\\le 0$\n",
        "\n",
        "Softmax activation: \n",
        "$f(h_i) = \\frac{\\exp(h_i)}{\\sum_j \\exp(h_j)}$\n",
        "\n",
        "Categorical cross-entropy loss:\n",
        "$\\mathcal{L} = -\\sum_t y^d_t \\log y_t$\n",
        "\n",
        "Stochastic Gradient Descent:\n",
        "$w_{ij} \\leftarrow w_{ij} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_{ij}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_bXT5x8M9Cd",
        "colab_type": "code",
        "outputId": "ca56293c-e37d-4fb8-9498-9709ab72a60c",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "\n",
        "x = Input(shape=(Nx,))\n",
        "y = Dense(20, activation='relu')(x)\n",
        "y = Dense(Ny, activation='softmax')(y)\n",
        "model = Model(inputs=x, outputs=y)\n",
        "model.compile(optimizer=optimizers.sgd(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/vipular/anaconda3/envs/vipulenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                60        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 123\n",
            "Trainable params: 123\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAyqM6U0M9Cm",
        "colab_type": "text"
      },
      "source": [
        "### Plotting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpiTEmxJM9Co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "def plotModel(model):\n",
        "    plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "    from IPython.display import Image\n",
        "    Image(retina=True, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNmbpH6tM9Cu",
        "colab_type": "text"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3NyeI8HM9Cw",
        "colab_type": "code",
        "outputId": "4fbacfca-6140-411a-f833-81ed2e62540d",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs=50) # validation_split = 0.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/vipular/anaconda3/envs/vipulenv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.5571 - acc: 0.8267\n",
            "Epoch 2/50\n",
            "150/150 [==============================] - 0s 144us/step - loss: 0.5452 - acc: 0.8267\n",
            "Epoch 3/50\n",
            "150/150 [==============================] - 0s 151us/step - loss: 0.5325 - acc: 0.8267\n",
            "Epoch 4/50\n",
            "150/150 [==============================] - 0s 136us/step - loss: 0.5213 - acc: 0.8267\n",
            "Epoch 5/50\n",
            "150/150 [==============================] - 0s 149us/step - loss: 0.5104 - acc: 0.8267\n",
            "Epoch 6/50\n",
            "150/150 [==============================] - 0s 149us/step - loss: 0.4992 - acc: 0.8267\n",
            "Epoch 7/50\n",
            "150/150 [==============================] - 0s 176us/step - loss: 0.4894 - acc: 0.8267\n",
            "Epoch 8/50\n",
            "150/150 [==============================] - 0s 162us/step - loss: 0.4806 - acc: 0.8267\n",
            "Epoch 9/50\n",
            "150/150 [==============================] - 0s 169us/step - loss: 0.4715 - acc: 0.8267\n",
            "Epoch 10/50\n",
            "150/150 [==============================] - 0s 370us/step - loss: 0.4630 - acc: 0.8267\n",
            "Epoch 11/50\n",
            "150/150 [==============================] - 0s 158us/step - loss: 0.4556 - acc: 0.8333\n",
            "Epoch 12/50\n",
            "150/150 [==============================] - 0s 183us/step - loss: 0.4481 - acc: 0.8333\n",
            "Epoch 13/50\n",
            "150/150 [==============================] - 0s 156us/step - loss: 0.4406 - acc: 0.8333\n",
            "Epoch 14/50\n",
            "150/150 [==============================] - 0s 169us/step - loss: 0.4339 - acc: 0.8333\n",
            "Epoch 15/50\n",
            "150/150 [==============================] - 0s 148us/step - loss: 0.4273 - acc: 0.8333\n",
            "Epoch 16/50\n",
            "150/150 [==============================] - 0s 177us/step - loss: 0.4206 - acc: 0.8333\n",
            "Epoch 17/50\n",
            "150/150 [==============================] - 0s 195us/step - loss: 0.4147 - acc: 0.8467\n",
            "Epoch 18/50\n",
            "150/150 [==============================] - 0s 176us/step - loss: 0.4097 - acc: 0.8467\n",
            "Epoch 19/50\n",
            "150/150 [==============================] - 0s 267us/step - loss: 0.4040 - acc: 0.8467\n",
            "Epoch 20/50\n",
            "150/150 [==============================] - 0s 151us/step - loss: 0.3980 - acc: 0.8467\n",
            "Epoch 21/50\n",
            "150/150 [==============================] - 0s 142us/step - loss: 0.3927 - acc: 0.8467\n",
            "Epoch 22/50\n",
            "150/150 [==============================] - 0s 174us/step - loss: 0.3882 - acc: 0.8467\n",
            "Epoch 23/50\n",
            "150/150 [==============================] - 0s 196us/step - loss: 0.3835 - acc: 0.8467\n",
            "Epoch 24/50\n",
            "150/150 [==============================] - 0s 184us/step - loss: 0.3793 - acc: 0.8467\n",
            "Epoch 25/50\n",
            "150/150 [==============================] - 0s 144us/step - loss: 0.3751 - acc: 0.8400\n",
            "Epoch 26/50\n",
            "150/150 [==============================] - 0s 154us/step - loss: 0.3715 - acc: 0.8467\n",
            "Epoch 27/50\n",
            "150/150 [==============================] - 0s 170us/step - loss: 0.3676 - acc: 0.8467\n",
            "Epoch 28/50\n",
            "150/150 [==============================] - 0s 172us/step - loss: 0.3644 - acc: 0.8467\n",
            "Epoch 29/50\n",
            "150/150 [==============================] - 0s 154us/step - loss: 0.3603 - acc: 0.8533\n",
            "Epoch 30/50\n",
            "150/150 [==============================] - 0s 176us/step - loss: 0.3570 - acc: 0.8533\n",
            "Epoch 31/50\n",
            "150/150 [==============================] - 0s 140us/step - loss: 0.3538 - acc: 0.8667\n",
            "Epoch 32/50\n",
            "150/150 [==============================] - 0s 186us/step - loss: 0.3508 - acc: 0.8667\n",
            "Epoch 33/50\n",
            "150/150 [==============================] - 0s 193us/step - loss: 0.3477 - acc: 0.8667\n",
            "Epoch 34/50\n",
            "150/150 [==============================] - 0s 161us/step - loss: 0.3446 - acc: 0.8667\n",
            "Epoch 35/50\n",
            "150/150 [==============================] - 0s 144us/step - loss: 0.3420 - acc: 0.8733\n",
            "Epoch 36/50\n",
            "150/150 [==============================] - 0s 166us/step - loss: 0.3395 - acc: 0.8667\n",
            "Epoch 37/50\n",
            "150/150 [==============================] - 0s 136us/step - loss: 0.3371 - acc: 0.8600\n",
            "Epoch 38/50\n",
            "150/150 [==============================] - 0s 148us/step - loss: 0.3350 - acc: 0.8600\n",
            "Epoch 39/50\n",
            "150/150 [==============================] - 0s 136us/step - loss: 0.3326 - acc: 0.8600\n",
            "Epoch 40/50\n",
            "150/150 [==============================] - 0s 170us/step - loss: 0.3303 - acc: 0.8600\n",
            "Epoch 41/50\n",
            "150/150 [==============================] - 0s 188us/step - loss: 0.3286 - acc: 0.8600\n",
            "Epoch 42/50\n",
            "150/150 [==============================] - 0s 187us/step - loss: 0.3266 - acc: 0.8600\n",
            "Epoch 43/50\n",
            "150/150 [==============================] - 0s 148us/step - loss: 0.3245 - acc: 0.8600\n",
            "Epoch 44/50\n",
            "150/150 [==============================] - 0s 162us/step - loss: 0.3228 - acc: 0.8600\n",
            "Epoch 45/50\n",
            "150/150 [==============================] - 0s 174us/step - loss: 0.3212 - acc: 0.8600\n",
            "Epoch 46/50\n",
            "150/150 [==============================] - 0s 119us/step - loss: 0.3192 - acc: 0.8600\n",
            "Epoch 47/50\n",
            "150/150 [==============================] - 0s 150us/step - loss: 0.3179 - acc: 0.8600\n",
            "Epoch 48/50\n",
            "150/150 [==============================] - 0s 161us/step - loss: 0.3160 - acc: 0.8600\n",
            "Epoch 49/50\n",
            "150/150 [==============================] - 0s 144us/step - loss: 0.3146 - acc: 0.8600\n",
            "Epoch 50/50\n",
            "150/150 [==============================] - 0s 129us/step - loss: 0.3134 - acc: 0.8600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSWKLcsJM9C4",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation\n",
        "Could you:\n",
        "- Generate 20 samples from each class\n",
        "- Normalize them with mean_train and std_train\n",
        "- Get Y_test as one hot encoded labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QB669hM9C7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test, Y_test_int = generateXY(20)\n",
        "X_test = normalizeX(X_test, mean_train, stddev_train)\n",
        "Y_test = np.array([oneHot(y,Ny) for y in Y_test_int])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "738j_68KM9DA",
        "colab_type": "code",
        "outputId": "4f429589-bccb-43a4-f450-5526a54f9bf7",
        "colab": {}
      },
      "source": [
        "def test_testData():\n",
        "    assert Y_test.shape==(60,3)\n",
        "    assert X_test.shape==(60,2)\n",
        "#     mn, sn = findMeanStddev(X_test)\n",
        "#     assert np.allclose(mn, np.zeros(2), atol=1)\n",
        "#     assert np.allclose(sn, np.ones(2), atol=1)\n",
        "    print(\"OK\")\n",
        "test_testData()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCMtdwWHM9DI",
        "colab_type": "code",
        "outputId": "4b113d85-93de-4ab1-fbf8-933d8292c109",
        "colab": {}
      },
      "source": [
        "## Evaluation\n",
        "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)  # Evaluate the model\n",
        "print('Accuracy :%0.3f'%accuracy)\n",
        "Y_pred = model.predict(X_test)\n",
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print( confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1)) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :0.867\n",
            "[[13  3  4]\n",
            " [ 1 19  0]\n",
            " [ 0  0 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}